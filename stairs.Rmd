---
title: "Staircase and elevator use"
author: "Nandor Hajdu"
date: "2023-01-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE,
                      message = FALSE)
```

```{r read_data}
library(tidyverse)
library(tidymodels)
library(janitor)
library(glmertree)
library(here)
library(parameters)

# Set up parallel processing
doParallel::registerDoParallel(cores = parallelly::availableCores())

theme_set(theme_light())

```

# The data

The dataset was collected in university buildings where participants provided information if they used the elevator or not. This was the outcome variable (choice). Other variables were used as predictors.
  The dataset contains 3588 observations from 288 participants, and 16 variables.

```{r read_data}
stairs_raw <- read_csv(here("data/behav.csv"))

stairs <-
  stairs_raw %>%
  clean_names() %>%
  filter(building_visited != "EgyÃ©b:") %>%
  mutate(id = as.factor(id),
         choice = as.factor(choice)) %>%
  # filter IDs with less than 8 entries
  group_by(id) %>%
  add_count() %>%
  ungroup() %>%
  filter(n >= 8) %>% 
  select(-n)

```

## Split data into training and test sets

```{r}

set.seed(12)

stairs_split <- group_initial_split(stairs, group = id)
stairs_train <- training(stairs_split)
stairs_test <- testing(stairs_split)

```


## Specify tidymodels recipe of feature engineering

```{r glmertree_recipe}

stairs_rec <- 
  recipe(stairs_train, formula = choice ~ .) %>%
  step_impute_mode(peers) %>% 
  step_string2factor(all_nominal_predictors()) %>% 
  step_impute_knn(health) %>% 
  step_scale(all_numeric_predictors()) %>% 
  step_zv(all_predictors())
  
print(stairs_rec)

```

## Execute the recipe and prepare the data for analysis

```{r recipe_prep}
rec_prepped <- prep(stairs_rec)
stairs_train_baked <- bake(rec_prepped, new_data = NULL)

glimpse(stairs_train_baked)

```

# Model fitting

```{r model_fitting, cache=TRUE}
stairs_res <-
  glmertree(
    choice ~ 1 | id | laziness + fatigue + luggage +
      elevator_speed + environmental_consciousness +
      temperature + appeal +
      number_of_people_waiting_for_the_elevator + peers +
      health + building_visited + speed +
      destination_floor,
    family = "binomial",
    data = stairs_train_baked
  )


# write_rds(stairs_res, file = here("model/stairs_res.rds"))
stairs_res <- read_rds(file = here("model/stairs_res.rds"))
```

# Checking model performance

```{r accuracy_metrics}

model_pred_tbl <- 
  tibble(
    truth = stairs_train_baked$choice,
    stairs_prob = predict(stairs_res)
  )

model_roc_auc <- 
  roc_auc(model_pred_tbl, truth, stairs_prob, event_level = "second")[[1,3]]

stairs_test_baked <- bake(rec_prepped, new_data = stairs_test)

glmertree_pred <- 
  predict(
        stairs_res,
        newdata = stairs_test_baked,
        type = "response",
        allow.new.levels = TRUE
  )

predictions <- 
  tibble(
    truth = stairs_test_baked$choice,
    stairs_prob = 1 - glmertree_pred,
    elevator_prob = glmertree_pred,
    pred = as.factor(if_else(glmertree_pred > 0.5, 1, 0))
    )

predictions %>% 
  conf_mat(truth, pred) %>% 
  autoplot("heatmap")

accuracy_metrics <- 
  bind_rows(
    accuracy(predictions, truth = truth, estimate = pred),
    sensitivity(predictions, truth = truth, estimate = pred),
    specificity(predictions, truth = truth, estimate = pred),
    precision(predictions, truth = truth, estimate = pred),
    recall(predictions, truth = truth, estimate = pred),
    bal_accuracy(predictions, truth, pred),
    kap(predictions, truth = truth, estimate = pred),
    f_meas(predictions, truth, pred),
    roc_auc(predictions, truth, stairs_prob),
    pr_auc(predictions, truth, stairs_prob)
  ) %>% 
  mutate(.estimate = signif(.estimate, 3),
         .estimator = NULL
  )

accuracy_metrics

roc_curve(predictions, truth, stairs_prob) %>% autoplot()
pr_curve(predictions, truth, stairs_prob) %>% autoplot()

```

The model had a good fit, with a ROC AUC of .91 on the test set. The sensitivity (.78) was somewhat lower than specificity (.89), suggesting that the model predicts the negative cases more accurately than the positive cases.

## Investigating variable importance
```{r}
# Define a function to shuffle a variable within a dataframe

df <- stairs_train_baked
tbl_names <- names(select(df, -c(id, choice)))
permutation_n <- 10

shuffle_var <- function(data, var) {
  data %>% 
    mutate({{var}} := sample(.data[[var]]))
}

all_aucs <- 
  crossing(variable = tbl_names,
         # Create replications
         index = 1:permutation_n) %>% 
  mutate(
         # Shuffle variable
           data = map(variable, ~shuffle_var(df, .x)),
         # Create new predictions
         pred = map(data,  ~predict(object = stairs_res, 
                                    newdata = .x, 
                                    type = "response",
                                    allow.new.levels = TRUE)),
         # Prepare prediction for roc calculation
         preds = map(pred, ~tibble(truth = df$choice,
                                   stairs_prob = 1 - .x)),
         # Calculate roc auc for each sample
         roc_auc = map_dbl(preds, ~roc_auc(.x, truth, stairs_prob) %>% 
                                   pull(.estimate)),
         )

roc_aucs <- 
  all_aucs %>% 
  group_by(variable) %>% 
  summarise(avg_roc_auc = mean(roc_auc),
            se_roc_auc = sd(roc_auc)/sqrt(n())) %>% 
  mutate(importance = model_roc_auc - avg_roc_auc)

# Visualize
roc_aucs %>% 
  mutate(variable = fct_reorder(variable, importance)) %>% 
  ggplot() +
  aes(y = variable, x = importance, 
      xmin = importance - se_roc_auc, xmax = importance + se_roc_auc) +
  geom_bar(stat = "identity") +
  geom_linerange() +
  labs(y = NULL, x = "Variable importance")

```

The permutation based variable importance shows that environmental consciousness was the most important predictor, then destination floor, peers, laziness, health, and the building visited. The other variables had little importance. 
